[
{
	"uri": "https://cobaltspeech.github.io/sdk-diatheke/getting-started/",
	"title": "Getting Started",
	"tags": [],
	"description": "",
	"content": "Installing the Diatheke Server Image The SDK communicates with a Diatheke Server instance using gRPC. Cobalt distributes a docker image that contains the diathekesvr binary and model files.\n Contact Cobalt to get a link to the image file in AWS S3. This link will expire in two weeks, so be sure to download the file to your own server.\n Download with the AWS CLI if you have it, or with curl:\nURL=\u0026#34;the url sent by Cobalt\u0026#34; IMAGE_NAME=\u0026#34;name you want to give the file (should end with the same extension as the url, usually bz2)\u0026#34; curl $URL -L -o $IMAGE_NAME Load the docker image\ndocker load \u0026lt; $IMAGE_NAME This will output the name of the image (e.g. diatheke-demo-en_us-16).\n Start the diatheke service\ndocker run -p 9002:9002 --name cobalt diathekesvr-demo-en_us-16 That will start listening for grpc commands on port 9002. You can replace --name cobalt with any name you want to give the docker container. The name simply provides a way to refer back to the running container.\n  Contents of the docker image  Base docker image : ubuntu:18.04 Additional dependencies  supervisor sox libsndfile1 language-pack-en  Servers  Cubic (ASR) Luna (TTS) Diatheke (Dialog)  Config Files  Cubic: /data/configs/cubicsvr.cfg.toml Luna: /data/configs/lunasvr.cfg.toml Diatheke: /data/configs/diathekesvr.cfg.toml  Model Directories  Cubic: /data/models/cubic Luna: /data/models/luna Diatheke: /data/models/diatheke   Installing the Diatheke SDK To install the Diatheke SDK, use git to clone the sdk-diatheke repository:\ngit clone https://github.com/cobaltspeech/sdk-diatheke.git Examples The sdk-diatheke repo contains example code with subdirectories for various languages to build demo client applications. Simply follow the README instructions for each language to build and run the sample applications.\n"
},
{
	"uri": "https://cobaltspeech.github.io/sdk-diatheke/using-diatheke-sdk/",
	"title": "Using Diatheke SDK",
	"tags": [],
	"description": "",
	"content": " This section describes how to use the SDK for currently supported languages. For unsupported languages, please see the Diatheke API reference, or contact us to request support for your preferred language.\nContents  Including the SDK Gives language-specific instructions about how to add the SDK to your project.\n    Error Handling Describes how errors from the SDK are reported.\n  \n Connecting to the Server Describes how to connect to a running Diatheke server instance.\n  \n Sessions Defines what a session is, and how to interact with it.\n \n Creating a Session How to start and end a new dialog using a Diatheke model to create a session.\n\n Event Stream The event stream notifies the client of significant events that occur in Diatheke.\n\n Push Text Provides text-based user input to a Diatheke session.\n\n Audio Input Describes how to provide audio-based user input to a session.\n\n Audio Output Describes how to receive audio output from a session.\n \n Streaming ASR Creating and using an ASR stream unrelated to any running sessions.\n  \n Streaming TTS Creating and using a TTS stream unrelated to any running sessions.\n   \n"
},
{
	"uri": "https://cobaltspeech.github.io/sdk-diatheke/using-diatheke-sdk/include/",
	"title": "Including the SDK",
	"tags": [],
	"description": "Gives language-specific instructions about how to add the SDK to your project.",
	"content": "Language-specific instructions to include the SDK in your project are given below.\nC++ To use the Diatheke SDK in a C++ project, you must first download the SDK. To help simplify the build process, the C++ SDK uses CMake, although it is possible to use a different build system with some additional work. Details for building and including the SDK in a C++ project are described in detail in this README file.\nGo The Go SDK supports Go modules and requires Go 1.12 or later. To use the SDK, import this package into your application:\nimport \u0026#34;github.com/cobaltspeech/sdk-diatheke/grpc/go-diatheke\u0026#34; Note When using Go, it is not necessary to download the SDK using git (unless you want to build the example code). The `go build` command will automatically fetch the sdk-diatheke code from GitHub to use in your Go project.  \n"
},
{
	"uri": "https://cobaltspeech.github.io/sdk-diatheke/using-diatheke-sdk/errors/",
	"title": "Error Handling",
	"tags": [],
	"description": "Describes how errors from the SDK are reported.",
	"content": " For the sake of clarity, most examples in the documentation do not fully demonstrate how to handle errors, preferring instead to focus on the topic at hand. However, the Diatheke SDK does report errors, and client applications should be prepared to handle them.\nA description of how errors are handled for each language is given below.\nC++ The C++ SDK uses exceptions to report errors. Errors originating from the SDK will have the class type Diatheke::ClientError, which inherits from the std::exception class. To handle these errors, simply create a try-catch block around the SDK code. For example:\ntry { // Call SDK functions in here. The function calls may be in this  // try block, or within functions that the try block calls. } catch (const Diatheke::ClientError \u0026amp;err) { // Handle the error here. The specific error message can be  // retrieved using err.what(). }  Go The Go SDK uses the built-in error type to return errors from functions (see here for general information about handling errors in Go). Most SDK functions will return an error in addition to their other return values. For example:\n// Create a new client connection client, err := diatheke.NewClient(\u0026#34;127.0.0.1:9002\u0026#34;) if err != nil { // Handle the error here. }"
},
{
	"uri": "https://cobaltspeech.github.io/sdk-diatheke/using-diatheke-sdk/connecting/",
	"title": "Connecting to the Server",
	"tags": [],
	"description": "Describes how to connect to a running Diatheke server instance.",
	"content": "Once you have the Diatheke server up and running, you are ready to create a client connection.\nFirst, you need to know the address (host:port) where the server is running. This document will assume the values 127.0.0.1:9002, but these can be replaced with your server address in actual code.\nDefault Connection The following code snippet connects to the server and queries its version. It uses our recommended default setup, expecting the server to be listening on a TLS encrypted connection.\n package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;github.com/cobaltspeech/sdk-diatheke/grpc/go-diatheke\u0026#34; ) const serverAddr = \u0026#34;127.0.0.1:9002\u0026#34; func main() { client, err := diatheke.NewClient(serverAddr) if err != nil { log.Fatal(err) } // Be sure to close the client when we are done with it.  defer client.Close() version, err := client.DiathekeVersion(context.Background()) if err != nil { log.Fatal(err) } fmt.Println(version) }  // File - main.cpp  #include \u0026#34;diatheke_client.h\u0026#34; #include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt; const char* serverAddr = \u0026#34;127.0.0.1:9002\u0026#34;; int main(int argc, char *argv[]) { Diatheke::Client client(serverAddr); std::string version = client.diathekeVersion(); std::cout \u0026lt;\u0026lt; \u0026#34;Diatheke version: \u0026#34; \u0026lt;\u0026lt; version \u0026lt;\u0026lt; std::endl; return 0; }    \nInsecure Connection It is sometimes required to connect to Diatheke server without TLS enabled (during debugging, for example). Note that if the server has TLS enabled, attempting to connect with an insecure client will fail.\nTo create an insecure connection, do the following when creating the client:\n client, err := diatheke.NewClient(serverAddr, diatheke.WithInsecure())  Diatheke::Client client(serverAddr, true);    \nClient Authentication In our recommended default setup, TLS is enabled in the gRPC setup, and when connecting to the server, clients validate the server\u0026rsquo;s SSL certificate to make sure they are talking to the right party. This is similar to how \u0026ldquo;https\u0026rdquo; connections work in web browsers.\nIn some setups, it may be desired that the server should also validate clients connecting to it and only respond to the ones it can verify. If your Diatheke server is configured to do client authentication, you will need to present the appropriate certificate and key when connecting to it.\nPlease note that in the client-authentication mode, the client will still also verify the server\u0026rsquo;s certificate, and therefore this setup uses mutually authenticated TLS. This can be done with:\n // certPerm and keyPem are the bytes of the client certificate and key // provided to you. client, err := diatheke.NewClient(serverAddr, diatheke.WithClientCert(certPem, keyPem))  // Currently unsupported in C++.    \n"
},
{
	"uri": "https://cobaltspeech.github.io/sdk-diatheke/using-diatheke-sdk/session/",
	"title": "Sessions",
	"tags": [],
	"description": "Defines what a session is, and how to interact with it.",
	"content": " A session represents all the components (ASR, TTS, NLU, etc.) necessary to carry on a conversation with Diatheke. A single session keeps track of a dialog\u0026rsquo;s current state, with all possible states being defined by a Diatheke model. The session transitions between states based on user input, which can be either text or audio. In response to user input, the Diatheke server will notify the client of events that occur as part of the transition, including TTS generated audio and requests to execute commands.\nThe following sections describe how to use use a session in the SDK.\nContents  Creating a Session   Event Stream   Push Text   Audio Input   Audio Output   "
},
{
	"uri": "https://cobaltspeech.github.io/sdk-diatheke/using-diatheke-sdk/streaming-asr/",
	"title": "Streaming ASR",
	"tags": [],
	"description": "Creating and using an ASR stream unrelated to any running sessions.",
	"content": " Not to be confused with a session\u0026rsquo;s audio input stream, a plain ASR stream is used to process audio and receive a transcript from Diatheke. This functionality is particularly useful for ASR tasks that fall outside of the normal dialog flow. For example, an application that wants to allow a user to record a note while in the middle of a task could use this stream to get a transcript that can be saved.\nSending audio on an ASR stream does not affect the state of any running sessions, or cause the dialog to transition between states. It essentially forwards the ASR request to the underlying Cubic engine and forwards the transcription back to the client. The fact that the ASR stream can be used without a session, makes it particularly useful for debugging audio issues.\nCreating an ASR Stream The ASR stream requires a Cubic model (defined in the Cubic server config file) to be specified at creation. The returned stream will be a bi-direction stream that allows the client code to push audio to the server, while concurrently receiving transcripts from the server as they become available.\nThere is no limit on the number of ASR streams that may be opened at a time, but as most the most common use case involves using a single input source (e.g., microphone), it usually won\u0026rsquo;t make sense to have more than one ASR stream running at a time.\n // Specify the Cubic model to use (not a Diatheke model) cubicModel := \u0026#34;1\u0026#34; // Create the bi-directional ASR stream stream, err := client.StreamASR(context.Background(), cubicModel)  // Specify the Cubic model to use (not a Diatheke model) std::string cubicModel = \u0026#34;1\u0026#34;; // Create the bi-directional ASR stream std::unique_ptr\u0026lt;Diatheke::ASRStream\u0026gt; stream = client.streamASR(cubicModel);    \nPushing Audio It is the client code\u0026rsquo;s responsibility to handle getting audio data, whether it is from a microphone, file, or some other source. Audio data should be formatted and encoded based on the specific ASR model being used for the stream. The audio data is then pushed to the server as demonstrated below.\nAfter all audio data has been pushed to the server, client code should be sure to call the AudioFinished() method to notify Diatheke that no more audio will be coming.\n // The audio data should be formatted as an array of bytes. buffer := make([]byte, 8192) // Get the audio data from a source. This could be a microphone, file, or // any other source. Here we assume the audio data was retrieved previously // and stored in our buffer.  // Push the audio data to the stream. This function may be called multiple // times. It is safe to call concurrently with the stream\u0026#39;s Receive() // method. if _, err := stream.Write(buffer); err != nil { fmt.Printf(\u0026#34;Error: %v\\n\u0026#34;, err) } // Be sure to notify Diatheke that no more audio will be coming when we // are done writing data. stream.AudioFinished()  // Store audio data as a string. Think of the string as an array of chars // or bytes (a char is one byte of data). std::string buffer; // Get the audio data from a source. This could be a microphone, file, or // any other source. Here we assume the audio data was retrieved previously // and stored in our buffer.  // Push the audio data to the stream. This function may be called multiple // times. It is safe to call concurrently with the stream\u0026#39;s waitForResult() // method. stream-\u0026gt;pushAudio(buffer.c_str(), buffer.size()); // Be sure to notify Diatheke that no more audio will be coming when we // are done writing data. stream-\u0026gt;finishAudio();    \nReceiving Transcriptions Transcripts are received over the same ASR stream used to push audio, as demonstrated below. It is safe to call both PushAudio() and Receive() concurrently (i.e., on different threads), however it is not safe to call the same method concurrently. For example, it is an error to call Receive() for the same stream simultaneously from two threads.\nThe transcript returned will include the transcript\u0026rsquo;s text and a confidence score, which is a measure of how confident the ASR engine is that the transcript matches the supplied audio. The confidence score will be between 0.0 and 1.0, with 1.0 meaning that the ASR engine is very confident that the transcript matches what was spoken.\nThe receiving end of the ASR stream will close after the sending side of the stream is closed (e.g., by calling AudioFinished()).\n for { // Wait for a transcription from the server. It is safe to call this  // method concurrently with the stream\u0026#39;s Write() method.  transcript, err := stream.Receive() // This indicates the stream has finished, which will happen  // after the stream\u0026#39;s AudioFinished() method is called or the  // context used to create the stream closes.  if err == io.EOF { break } if err != nil { fmt.Printf(\u0026#34;Error: %v\\n\u0026#34;, err) return } // Display the transcript  fmt.Printf(\u0026#34;ASR Response:\\n\u0026#34;) fmt.Printf(\u0026#34; Transcription: %s\\n\u0026#34;, transcript.Text) fmt.Printf(\u0026#34; Confidence Score: %v\\n\\n\u0026#34;, transcript.ConfidenceScore) }  // Wait for a transcription from the server. It is safe to call this // method concurrently with the stream\u0026#39;s pushAudio() method. The // waitForResult() method will return false after the stream\u0026#39;s // finishAudio() method has been called. cobaltspeech::diatheke::ASRResponse result; while (stream-\u0026gt;waitForResult(\u0026amp;result)) { // Display the transcript  std::cout \u0026lt;\u0026lt; \u0026#34;ASR Response:\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34; Transcription: \u0026#34; \u0026lt;\u0026lt; result.text() \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34; Confidence Score: \u0026#34; \u0026lt;\u0026lt; result.confidence_score() \u0026lt;\u0026lt; std::endl \u0026lt;\u0026lt; std::endl; }    \n"
},
{
	"uri": "https://cobaltspeech.github.io/sdk-diatheke/using-diatheke-sdk/streaming-tts/",
	"title": "Streaming TTS",
	"tags": [],
	"description": "Creating and using a TTS stream unrelated to any running sessions.",
	"content": " Not to be confused with a session\u0026rsquo;s audio output stream, a plain TTS stream is used to synthesize speech unrelated to any currently running sessions or Diatheke models. This means that, unlike audio output from a session which is sent to the client in response to user input as defined in the model, the audio output for a plain TTS stream is returned to the client immediately after the TTS request is made.\nThis functionality is provided mainly as a convenience. There may be some situations where it is useful to synthesize audio unrelated to a running session (such as debugging). For the majority of situations, Cobalt recommends embedding TTS replies in the Diatheke model itself, so that they may be returned as part of the normal dialog flow for a session.\nCreating the TTS Stream The TTS stream requires a Luna model (defined in the Luna server config file) and the text to synthesize to be specified at creation. The returned stream will receive audio data from the server until synthesis is complete and the stream is closed.\n // Specify the Luna model to use (not a Diatheke model) lunaModel := \u0026#34;1\u0026#34; sentence := \u0026#34;this is the text to synthesize\u0026#34; // Create the TTS stream stream, err := client.StreamTTS(context.Background(), lunaModel, sentence)  // Specify the Luna model to use (not a Diatheke model) std::string lunaModel = \u0026#34;1\u0026#34;; std::string sentence = \u0026#34;this is the text to synthesize\u0026#34;; // Create the TTS stream std::unique_ptr\u0026lt;Diatheke::TTSStream\u0026gt; stream = client.streamTTS(lunaModel, sentence);    \nReceiving Audio The only data returned on the TTS stream will be audio data. The simplest way to receive it is to set up a loop to receive and process the data until the stream is closed, as shown below.\nThe TTS generated audio data will be formatted and encoded based on the specific TTS model being used for the stream. It is the client code\u0026rsquo;s responsibility to handle the output audio, whether it sends it to an output device (e.g., speakers), saves it to a file, or does some other processing of the audio data.\n // Receive data from the TTS stream until it is closed, which will happen // when synthesis is complete, or the context used to create the stream // is cancelled. for { // Wait for data from the server  msg, err := stream.Recv() // This indicates the stream has finished, which will happen  // when the session ends or the context used to create the stream  // closes.  if err == io.EOF { break } if err != nil { fmt.Printf(\u0026#34;Error: %v\\n\u0026#34;, err) return } // Use the audio data, which will be an array of bytes.  fmt.Printf(\u0026#34;TTS Data size (bytes): %v\\n\u0026#34;, len(msg.Data)) } fmt.Printf(\u0026#34;Synthesis complete.\\n\u0026#34;)  // Receive data from the TTS stream until it is closed, which will happen // when synthesis is complete. cobaltspeech::diatheke::TTSResponse response; while (stream-\u0026gt;waitForAudio(\u0026amp;response)) { // Use the audio data, which will be given as a string. Think of it as an  // array of chars (a char is one byte).  std::string audioData = response.data(); std::cout \u0026lt;\u0026lt; \u0026#34;TTS Data size (bytes): \u0026#34; \u0026lt;\u0026lt; audioData.size() \u0026lt;\u0026lt; std::endl; } std::cout \u0026lt;\u0026lt; \u0026#34;Synthesis complete.\u0026#34; \u0026lt;\u0026lt; std::endl;    \n"
},
{
	"uri": "https://cobaltspeech.github.io/sdk-diatheke/using-diatheke-sdk/session/create-session/",
	"title": "Creating a Session",
	"tags": [],
	"description": "How to start and end a new dialog using a Diatheke model to create a session.",
	"content": " New sessions may be created using a Diatheke model, which defines what is allowed in the session\u0026rsquo;s conversation. For example, if the model defines an intent that includes the phrase \u0026ldquo;check account balance\u0026rdquo;, a user may speak that phrase and expect Diatheke to respond. If, however, the user speaks the phrase \u0026ldquo;buy pizza\u0026rdquo;, and that intent is not in the model, Diatheke may ignore the phrase or reply with an error message, such as \u0026ldquo;I didn\u0026rsquo;t understand that\u0026rdquo;.\nTo begin a new dialog, create a session by doing the following:\n // The Diatheke model ID is defined in the Diatheke server config file. diathekeModelID := \u0026#34;1\u0026#34; sessionID, err := client.NewSession(context.Background(), diathekeModelID) // Be sure to close the session when we are done with it. defer client.EndSession(context.Background(), sessionID)  // The Diatheke model ID is defined in the Diatheke server config file. std::string diathekeModelID = \u0026#34;1\u0026#34;; std::string sessionID = client.newSession(diathekeModelID); // Be sure to close the session when we are done with it. client.endSession(sessionID);    \nCreating a new session will return a session ID, which is required for all the session functions in the SDK.\nAs shown in the example, sessions should be closed when they are no longer in use. This has the side-effect of freeing resources related to the session on the server.\nIt should also be noted that simply exiting the application or closing the client will not end a session on the server. This is by design - in some situations, it may be convenient to save the sessionID and resume session interactions after creating a new client connection. For example, it might not make sense to preserve the network connection for a long running commands. The client code could save the session ID, close the client connection, execute the command, then restart the client and resume the session when the command has finished.\nThe Session Object For those who prefer a more object oriented approach to interacting with sessions, the SDK provides a convenience class that wraps the client and session ID. The session object includes all the session functions as class members.\n // Wrap the session ID in the convenience class session := diatheke.Session{ ID: sessionID, Parent: client, } // Use session methods without the ID as a parameter err := session.EndSession(context.Background());  // Wrap the session ID in the convenience class Diatheke::Session session(sessionID, \u0026amp;client); // Use session methods without the ID as a parameter session.EndSession();    \n"
},
{
	"uri": "https://cobaltspeech.github.io/sdk-diatheke/using-diatheke-sdk/session/event-stream/",
	"title": "Event Stream",
	"tags": [],
	"description": "The event stream notifies the client of significant events that occur in Diatheke.",
	"content": " Diatheke server uses an event driven architecure to notify clients when significant events happen for a session. These include Recognize, Reply, and Command events. These events are delivered to the client via a session\u0026rsquo;s event stream.\nCreating the Event Stream The following demonstrates how to create a an event stream for a session.  // Create the stream using the client and session ID. stream, err := client.SessionEventStream(context.Background(), sessionID) // OR create the stream using the Session object stream, err := session.EventStream(context.Background())  std::unique_ptr\u0026lt;Diatheke::EventStream\u0026gt; stream; // Create the stream using the client and session ID stream = client.sessionEventStream(sessionID); // OR create the stream using the session object stream = session.eventStream();    \nThis creates a server stream that will deliver events to the client. The stream will be closed by the server when the session ends.\nEvent Handling The recommended way to handle events from the stream is to setup a loop that waits for the next event, then handles the event based on its type:\n for { // Wait for the next event from the server  event, err := eventStream.Recv() // This indicates the stream has finished, which will happen  // when the session ends or the context used to create the stream  // closes.  if err == io.EOF { break } // Handle any other errors  if err != nil { fmt.Printf(\u0026#34;Error: %v\\n\u0026#34;, err) break } // Handle the event based on its type.  switch e := event.Result.(type) { case *diathekepb.DiathekeEvent_Recognize: handleRecognizeEvent(e.Recognize) case *diathekepb.DiathekeEvent_Reply: handleReplyEvent(e.Reply) case *diathekepb.DiathekeEvent_Command: handleCommandEvent(e.Command, manager.Session) default: fmt.Printf(\u0026#34;Error: received unknown event type from Diatheke\\n\u0026#34;) } }  // Receive events from the event stream until it is closed, which will // happen when the session ends, or the context used to create the stream // closes. cobaltspeech::diatheke::DiathekeEvent event; while (eventStream-\u0026gt;waitForEvent(\u0026amp;event)) { // Check for the event type  if (event.has_recognize()) { handleRecognizeEvent(event.recognize()); } else if (event.has_reply()) { handleReplyEvent(event.reply()); } else if (event.has_command()) { handleCommandEvent(event.command(), eventStream.get()); } else { std::cerr \u0026lt;\u0026lt; \u0026#34;Received unknown event type from Diatheke\u0026#34; \u0026lt;\u0026lt; std::endl; } } // It is good practice to close the event stream when we are done with it. // This will allow the server to report errors related to the stream, if // there were any. eventStream-\u0026gt;close();    \nRecognize Event The Recognize event is sent when Diatheke has received user input. In the case of text-based input, the text of the event will be the same as what was typed by the user. In the case of audio-based input, the event is sent when enough audio has been processed that a transcription is available. In this case, the text of the event will be the ASR transcription. The event will also indicate whether the user input was recognized by the NLU as a valid intent or entity.\nMost often, this event will be used by clients to give some kind of visual indication to the user about whether their input was recognized or not.\n func handleRecognizeEvent(event *diathekepb.RecognizeEvent) { // Check if Diatheke recognized the last input as valid.  if event.ValidInput { fmt.Printf(\u0026#34;Valid input: %s\\n\u0026#34;, event.Text) } else { fmt.Printf(\u0026#34;Invalid input: %s\\n\u0026#34;, event.Text) } }  void handleRecognizeEvent(const cobaltspeech::diatheke::RecognizeEvent \u0026amp;event) { if(event.valid_input()) { std::cout \u0026lt;\u0026lt; \u0026#34;Valid input: \u0026#34; \u0026lt;\u0026lt; event.text() \u0026lt;\u0026lt; std::endl; } else { std::cout \u0026lt;\u0026lt; \u0026#34;Invalid input: \u0026#34; \u0026lt;\u0026lt; event.text() \u0026lt;\u0026lt; std::endl; } }    \nReply Event The Reply event is sent when, based on the session\u0026rsquo;s model, Diatheke has a reply for the user. This might happen when Diatheke needs additional information from the user, in which case the text of the Reply event will be a prompt. This event may also be sent to give the user information, such as after running a command. The text for all Reply events is defined in the Diatheke model.\nMost often, this event will be used by clients to give some kind of visual feedback to the user.\n func handleReplyEvent(event *diathekepb.ReplyEvent) { fmt.Printf(\u0026#34;Reply text: %s\\n\u0026#34;, event.Text) }  void handleReplyEvent(const cobaltspeech::diatheke::ReplyEvent \u0026amp;event) { std::cout \u0026lt;\u0026lt; \u0026#34;Reply text: \u0026#34; \u0026lt;\u0026lt; event.text() \u0026lt;\u0026lt; std::endl; }    \nCommand Event The Command event is sent when Diatheke wants the client to execute a command. This happens after the corresponding intent and entities have been recognized, and Diatheke is in a state where the command has all the required information to execute (as defined by the Diatheke model).\nFrom the client perspective, this is the most important event that will come from Diatheke because it is what prompts the client code to do useful work by executing the commands.\n func handleCommandEvent(event *diathekepb.CommandEvent, session diatheke.Session) { // Use the command ID and parameters to execute a task.  fmt.Printf(\u0026#34;Command ID: %v\\n\u0026#34;, event.CommandId) fmt.Printf(\u0026#34;Parameters:\\n\u0026#34;) for param, value := range event.Parameters { fmt.Printf(\u0026#34; %v = %v\\n\u0026#34;, param, value) } fmt.Printf(\u0026#34;\\n\u0026#34;) // After executing the command, be sure to notify Diatheke that  // we are done. This is important to do so that dialog flow may continue  // after the command is finished.  status := \u0026amp;diathekepb.CommandStatus{ SessionId: session.ID, CommandId: event.CommandId, // Indicate success or failure.  ReturnStatus: diathekepb.CommandStatus_SUCCESS, // If the ReturnStatus above is CommandStatus_FAILURE,  // the ErrorMessageText field of this struct should also be populated.  // ErrorMessageText: \u0026#34;some message describing the error\u0026#34;,  // Return parameters as necessary. Depending on the Diatheke model,  // some commands may be expected to have output.  OutputParameters: event.Parameters, // Internal data that should always be set from the original command  // event.  CommandStateId: event.CommandStateId, } if err := session.CommandFinished(context.Background(), status); err != nil { fmt.Printf(\u0026#34;Error: %v\\n\u0026#34;, err) } }  void handleCommandEvent(const cobaltspeech::diatheke::CommandEvent \u0026amp;event, Diatheke::EventStream *stream) { // Use the command ID and parameters to execute a task.  std::cout \u0026lt;\u0026lt; \u0026#34;Command ID: \u0026#34; \u0026lt;\u0026lt; event.command_id() \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Parameters:\u0026#34; \u0026lt;\u0026lt; std::endl; for (const auto \u0026amp;pair : event.parameters()) { std::string param = pair.first; std::string value = pair.second; std::cout \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; param \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; value \u0026lt;\u0026lt; std::endl; } std::cout \u0026lt;\u0026lt; std::endl; Diatheke::CommandStatus status(event); // Set the status code to indicate whether the command failed  status.setStatusCode(Diatheke::CommandStatus::SUCCESS); // If the status code is FAILURE, the error message should also be set  // status.setError(\u0026#34;some message describing the error\u0026#34;);  // Update return parameters as necessary. For example:  // status.setStringParam(\u0026#34;some key\u0026#34;, \u0026#34;some value\u0026#34;);  // Notify Diatheke that the command is finished. This is important  // to do so that dialog flow may continue after the command is  // finished.  eventStream-\u0026gt;commandFinished(status); }    \nCommand Finished After receiving a Command event, it is important to notify Diatheke when command execution has completed. Not only does it let Diatheke know the final command status (success or failure), but calling CommandFinished allows Diatheke to continue processing and execute any additional commands or replies as defined by the Diatheke model.\nFor long running commands, it should be noted that calling CommandFinished will restore the dialog to the state Diatheke was at when the Command event was sent. This allows dialog to remain responsive to other intents while waiting for long-running commands to finish.\n // Use the client err := client.CommandFinished(context.Background(), status) // OR use the Session object err := session.CommandFinished(context.Background(), status)  // Use the client client.commandFinished(sessionID, status); // OR use the Session object session.commandFinished(status); // OR use the EventStream object stream-\u0026gt;commandFinished(status);    \nEvent flow Audio Based For an audio-based dialog, the flow events is shown below. Based on the Diatheke model, the server will send events in response to recognized audio and intents.\nmermaid.initialize({startOnLoad:true}); sequenceDiagram; Note left of Client: Client records\naudio Client - Diatheke: Audio input Client - Diatheke: Audio input Client - Diatheke: Audio input Note right of Diatheke: ASR createstranscript Note right of Diatheke: NLU interpretstranscript Diatheke -- Client: Recognize event Note right of Diatheke: Model findscommand for intent Diatheke -- Client: Command event Note left of Client: Client executes\ncommand Client - Diatheke: CommandFinished Note right of Diatheke: Model findsSay actionafter command Diatheke -- Client: Reply event  Text Based For a text-based dialog, the flow events is shown below. As with the audio-based dialog, the specific type and number of events will depend on the Diatheke model. mermaid.initialize({startOnLoad:true}); sequenceDiagram; Note left of Client: Client sends\ntext Client - Diatheke: Text input Note right of Diatheke: NLU interpretstext Diatheke -- Client: Recognize event Note right of Diatheke: Model findscommand for intent Diatheke -- Client: Command event Note left of Client: Client executes\ncommand Client - Diatheke: CommandFinished Note right of Diatheke: Model findsanother command Diatheke -- Client: Command event Note left of Client: Client executes\ncommand Client - Diatheke: CommandFinished Note right of Diatheke: Model findsSay actionafter command Diatheke -- Client: Reply event \n"
},
{
	"uri": "https://cobaltspeech.github.io/sdk-diatheke/using-diatheke-sdk/session/push-text/",
	"title": "Push Text",
	"tags": [],
	"description": "Provides text-based user input to a Diatheke session.",
	"content": "There are two ways to provide user input to a session: audio and text. Text input is sent using the PushText method as described below. Diatheke will respond with appropriate events on the session\u0026rsquo;s event stream.\n // Push text using the client and sessionID err := client.PushText(context.Background(), sessionID, \u0026#34;What\u0026#39;s the capital of Assyria?\u0026#34;) // OR push text using the session object err := session.PushText(context.Background(), \u0026#34;What\u0026#39;s the capital of Assyria?\u0026#34;)  // Push text using the client and sessionID client.pushText(sessionID, \u0026#34;What\u0026#39;s the capital of Assyria?\u0026#34;); // OR push text using the session object session.pushText(\u0026#34;What\u0026#39;s the capital of Assyria?\u0026#34;);    \nNote It is perfectly acceptable to use the `PushText` method while also using audio input. The choice to do so is left as a design decision for individual applications.  \n"
},
{
	"uri": "https://cobaltspeech.github.io/sdk-diatheke/using-diatheke-sdk/session/audio-input/",
	"title": "Audio Input",
	"tags": [],
	"description": "Describes how to provide audio-based user input to a session.",
	"content": " In addition to pushing text, a client may provide the session input by using audio.\nCreating the Audio Input Stream To provide the session with audio input, the client code should first create the input stream. For a given session, only a single audio input stream should be open at a time, but it perfectly acceptable to open and close multiple audio streams over the course of a single session.\n // Create the stream using the client and session ID stream, err := client.StreamAudioInput(context.Background(), sessionID) // OR create the stream using the Session object stream, err := session.StreamAudioInput(context.Background())  std::unique_ptr\u0026lt;Diatheke::AudioInputStream\u0026gt; stream; // Create the stream using the client and session ID stream = client.streamAudioInput(sessionID); // OR create the stream using the Session object stream = session.streamAudioInput();    \nPushing Audio It is the client code\u0026rsquo;s responsibility to handle getting audio data, whether it is from a microphone, file, or some other source. Audio input should be formatted and encoded based on the specific ASR model being used for the session (as defined in the Diatheke server config file). The audio data may then be sent to the server using the stream created previously.\n // The audio data should be formatted as an array of bytes. buffer := make([]byte, 8192) // Get the audio data from a source. This could be a microphone, file, or // any other source. Here we assume the audio data was retrieved previously // and stored in our buffer.  // Push the audio data to the input stream. This function may be called // multiple times. bytesWritten, err := stream.Write(buffer); // Be sure to notify Diatheke that no more audio will be coming when we // are done writing data. err := stream.Finish();  // Store audio data as a string. Think of the string as an array of chars // or bytes (a char is one byte of data). std::string buffer; // Get the audio data from a source. This could be a microphone, file, or // any other source. Here we assume the audio data was retrieved previously // and stored in our buffer.  // Push the audio data to the input stream. This function may be called // multiple time. stream-\u0026gt;pushAudio(buffer.c_str(), buffer.size()); // Be sure to notify Diatheke that no more audio will be coming when we // are done writing data. stream-\u0026gt;finished();    \nAfter all audio data has been pushed to the server, client code should be sure to call the Finish() method to notify Diatheke that no more audio will be coming.\nTranscriptions for session audio input are not returned as part of the audio input stream. They are returned as Recognize events on the session\u0026rsquo;s event stream.\n"
},
{
	"uri": "https://cobaltspeech.github.io/sdk-diatheke/using-diatheke-sdk/session/audio-output/",
	"title": "Audio Output",
	"tags": [],
	"description": "Describes how to receive audio output from a session.",
	"content": " The audio output stream is the audio version of the Reply event. When Diatheke wants to reply to user input, this stream will receive notifications with the text of the reply, and the TTS generated audio bytes.\nCreating the Audio Reply Stream Before any audio for the session can be received, the client code should first create the audio reply stream. Similar to the event stream, this stream will be closed by the server when the session ends.\n // Create the stream using the client and session ID stream, err := client.StreamAudioReplies(context.Background(), sessionID) // OR create the stream using the Session object stream, err := session.StreamAudioReplies(context.Background())  // The stream is returned as a std::unique_ptr std::unique_ptr\u0026lt;Diatheke::AudioReplyStream\u0026gt; stream; // Create the stream using the client and session ID stream = client.streamAudioReplies(sessionID); // OR create the stream using the Session object stream = session.streamAudioReplies();    \nReceiving Audio A single reply from Diatheke will have multiple messages on the audio reply stream. First, it will receive a message containing the text of the reply. Then, it will receive one or more messages containing the TTS generated audio data. Lastly, it will receive an empty message that contains no data, but serves as an indicator that the reply has finished TTS generation and that no more data will be coming for the current reply. An example showing how to handle these cases is given below.\nThe TTS generated audio data will be formatted and encoded based on the specific TTS model being used for the session (as defined in the Diatheke server config file). It is the client code\u0026rsquo;s responsibility to handle the output audio, whether it sends it to an output device (e.g., speakers), saves it to a file, or some other processing of the audio data.\n for { // Wait for replies from the server until the stream is closed,  // which will happen when the session is closed or the stream\u0026#39;s  // context ends.  msg, err := stream.Recv() // This indicates the stream has finished, which will happen  // when the session ends or the context used to create the stream  // closes.  if err == io.EOF { break } if err != nil { fmt.Printf(\u0026#34;Error: %v\\n\u0026#34;, err) return } // Check which message type we have received.  switch reply := msg.OutputMessage.(type) { case *diathekepb.AudioReply_Text: // The text of the reply comes first for a reply from Diatheke.  fmt.Printf(\u0026#34;Text: %s\\n\u0026#34;, reply.Text) case *diathekepb.AudioReply_Data: // Audio data is received until speech synthesis is done.  fmt.Printf(\u0026#34;Data size (bytes): %v\\n\u0026#34;, len(reply.Data)) case *diathekepb.AudioReply_End: // This message comes at the end of a reply, after speech synthesis  // is complete. It has no data.  fmt.Printf(\u0026#34;Reply complete\\n\u0026#34;) default: fmt.Printf(\u0026#34;received unexpected AudioReply type\\n\u0026#34;) }  // Wait for replies until the stream is closed, which will happen when // the session is closed or the stream\u0026#39;s context stops. cobaltspeech::diatheke::AudioReply reply; while (stream-\u0026gt;waitForReply(\u0026amp;reply)) { // Check which message type we have received  if (reply.has_text()) { // The text of the reply comes first for a reply from Diatheke.  std::cout \u0026lt;\u0026lt; \u0026#34;Text: \u0026#34; \u0026lt;\u0026lt; reply.text() \u0026lt;\u0026lt; std::endl; } else if (reply.has_data()) { // Audio data is received until speech synthesis is done.  // It is returned as a string (think of it as an array of  // chars/bytes).  std::string audioData = reply.data(); std::cout \u0026lt;\u0026lt; \u0026#34;Data size (bytes): \u0026#34; \u0026lt;\u0026lt; audioData.size() \u0026lt;\u0026lt; std::endl; } else if (reply.has_end()) { // This message comes at the end of a reply, after speech synthesis  // is complete. It has no data.  std::cout \u0026lt;\u0026lt; \u0026#34;Reply complete\u0026#34; \u0026lt;\u0026lt; std::endl; } else { std::cerr \u0026lt;\u0026lt; \u0026#34;received unexpected AudioReply type\u0026#34; \u0026lt;\u0026lt; std::endl; } } stream-\u0026gt;close();    \n"
},
{
	"uri": "https://cobaltspeech.github.io/sdk-diatheke/protobuf/",
	"title": "Diatheke API Reference",
	"tags": [],
	"description": "",
	"content": " The Diatheke API is defined using gRPC and protocol buffers. This section of the documentation is auto-generated from the protobuf file. It describes the data types and functions defined in the spec. The \u0026ldquo;messages\u0026rdquo; below correspond to the data structures to be used, and the \u0026ldquo;service\u0026rdquo; contains the methods that can be called.\ndiatheke.proto Service: Diatheke Service that implements the Cobalt Diatheke Dialog Management API.\n   Method Name Request Type Response Type Description     Version Empty VersionResponse Queries the Version of the Server.   Models Empty ModelsResponse Models will return a list of available versions. Model values from this list may be used in NewSession calls.   NewSession NewSessionRequest SessionID Requests a new session with the given config and returns the session ID, which is required for other rpc methods.   EndSession SessionID Empty Terminates an existing session and closes any open event streams. It is an error if the SessionEndRequest has an invalid SessionID.   SessionEventStream SessionID DiathekeEvent Requests a new event stream for the given session.   CommandFinished CommandStatus Empty Notify Diatheke when a command has completed so that it may update the dialog state. The initial command request will come as part of a DiathekeEvent. While not strictly required (depeding on the model and command), it is best practice to always call this method when a command is complete. Cases where it is required include when the command has output parameters, or when the command is followed by another action in the Diatheke model.   StreamAudioInput AudioInput Empty Begin an audio input stream for a session. The first message to the server should specify the sessionID, with binary audio data pushed for every subsequent message. As the audio is recognized, Diatheke will respond with appropriate events on the session\u0026rsquo;s event stream.  While it is allowed to call this multiple times during a single session, clients should never have multiple audio input streams running concurrently for the same session (the audio may mix and result in unpredictable behavior). Previous audio streams should always be closed before starting a new one.   StreamAudioReplies SessionID AudioReply Create an audio reply stream for a session. The returned stream will receive replies (\u0026ldquo;say\u0026rdquo; entries in the Diatheke model) from the server as they occur in the conversation. For each \u0026ldquo;say\u0026rdquo; entry, the stream will first receive the text to synthesize (defined by the model), followed by one or more messages containing the synthesized audio bytes. The \u0026ldquo;say\u0026rdquo; entry will end with a message indicating that TTS for that entry is complete. NOTE: The text in the first message of an audio reply is the same that will be received in the session\u0026rsquo;s event stream.   PushText PushTextRequest Empty Push text to Diatheke as part of the conversation for a session. Diatheke will respond with an appropriate event on the session\u0026rsquo;s event stream based on whether the given text was recognized as a valid intent or not.   StreamASR ASRRequest ASRResponse Manually run streaming ASR unrelated to any session by pushing audio data to the server on the audio stream. As transcriptions become available, the server will return them on the ASRResponse stream. The transcriptions may then be used for, e.g., the PushText method. This function is provided as a convenience.   StreamTTS TTSRequest TTSResponse Manually run streaming TTS. The Audio stream will receive binary audio data as it is synthesized and will close automatically when synthesis is complete. This function is provided as a convenience.    Message: ASRRequest Request for streaming ASR unrelated to a session.\n   Field Type Label Description     model string  The model to use for ASR. This message should always be sent before any audio data is sent.\n   audio bytes  Audio data to process. The encoding of the data should match what was specified in the Diatheke server configuration. NOTE: If the audio data is empty, the server may interpret it as the end of the stream and stop accepting further messages.\n    Message: ASRResponse ASRResponse contains speech recognition results.\n   Field Type Label Description     text string  Text is the Cubic engine\u0026rsquo;s formatted transcript of pushed audio. This field will be the 1-best alternative.\n   confidence_score double  The confidence score is a floating point number between 0.0 - 1.0. A score of 1.0 indicates that the ASR engine is 100% confident in the transcription.\n    Message: AudioInput Provides input audio data for StreamAudioInput. The first message sent must contain the session ID only. All subsequent messages must contain audio data only.\n   Field Type Label Description     session_id string  Session ID returned from the NewSession call.\n   data bytes  Audio data to process. The encoding of the data should match what was specified in the Diatheke server configuration. NOTE: If the audio data is empty, the server may interpret it as the end of the stream and stop accepting further messages.\n    Message: AudioReply An AudioReply is the verbal and textual reply that Diatheke returns as part of a conversation (not to be confused with the server concepts of request and response).\n   Field Type Label Description     label string  The label defined in the Diatheke model. Identifies which \u0026ldquo;say\u0026rdquo; entry in the model this message corresponds to.\n   text string  The reply text as defined in the Diatheke model. This is the first message that will be received for an AudioReply. It contains the same text as the corresponding ReplyEvent in the session\u0026rsquo;s event stream.\n   data bytes  The audio data from TTS. There can be any number of these messages for an AudioReply after the first text message and before the final end message. The encoding of the data will match what was specified in the server configuration.\n   end Empty  Indicates that TTS has finished streaming audio for the reply. This is the last message that will be received for an AudioReply.\n    Message: CommandEvent A CommandEvent occurs when Diatheke wants the client to execute the given command.\n   Field Type Label Description     command_id string  ID of the command that should be run. i.e. \u0026ldquo;COM01\u0026rdquo; for Command #01.\n   parameters CommandEvent.ParametersEntry repeated A generic map of parameters (name, value). The parameters are defined in the Diatheke model. Depending on the command, these parameters should be sent back with the CommandStatus update.\n   command_state_id string  ID to keep track of the dialog state when the command is requested. This field is required in the CommandStatus message so that Diatheke can correctly update the dialog state when CommandFinished is called.\n    Message: CommandEvent.ParametersEntry    Field Type Label Description     key string  \n   value string  \n    Message: CommandStatus The final status of an executed command.\n   Field Type Label Description     session_id string  session_id should be the same as the status id returned from NewSessionResponse.\n   command_id string  ID of the command as given in the RunCommand object.\n   return_status CommandStatus.StatusCode  \n   output_parameters CommandStatus.OutputParametersEntry repeated The populated output parameters from the RunCommand object. For example, the map might contain the entry \u0026ldquo;temperature\u0026rdquo;, which was populated with a value of \u0026ldquo;30\u0026rdquo; after the command finished.\n   error_message_text string  Set this field with an error message if an a error occured while executing the command.\n   command_state_id string  State ID from the original CommandEvent. This field is required for Diatheke to correctly update the dialog state when CommandFinished is called.\n    Message: CommandStatus.OutputParametersEntry    Field Type Label Description     key string  \n   value string  \n    Message: DiathekeEvent An event from Diatheke in response to either recognized audio or submitted text.\n   Field Type Label Description     command CommandEvent  Indicates Diatheke found an actionable state in the dialog, and requests the client to perform the given command.\nWhile not strictly required (depeding on the model and command), it is best practice to always call CommandFinished after receiving this event so that Diatheke can update the dialog state when the command is complete. Cases where it is required include when the command has output parameters, or when it is followed by another action in the Diatheke model.\n   recognize RecognizeEvent  An event indicating whether pushed text and audio was recognized by ASR and/or Diatheke.\n   reply ReplyEvent  The textual reply from Diatheke in the conversation (not to be confused with the server concepts of request and response). For example, this could be a question to solicit more information from the user, a status report, or any other reply defined by the Diatheke model. The text of this message is also provided in the AudioReply stream (if one is open).\n    Message: Empty This message is empty and has no fields.\nMessage: ModelsResponse The message sent by the server in response to a Models request. Returns an array of model names.\n   Field Type Label Description     models string repeated Array of models available for use.\n    Message: NewSessionRequest Request for the NewSession call.\n   Field Type Label Description     model string  For applications that have more than one model to use for ASR/NLU. ASR grammar can vary between models, as well as sets of commands. Some applications will only have one model.\n    Message: PushTextRequest Request to push text to Diatheke as part of a conversation.\n   Field Type Label Description     session_id string  Session ID returned from the NewSession call.\n   text string  User input. This could be a transcription from manually run ASR, text selected from a dropdown list, entered in a prompt, etc.\n    Message: RecognizeEvent A RecognizeEvent occurs if a session\u0026rsquo;s audio input has a transcription available, or if the PushText method was called. In both cases, the event will indicate whether the text was recognized as a valid intent by the Diatheke model.\n   Field Type Label Description     text string  The pushed text or transcription of audio sent to Diatheke.\n   valid_input bool  True if the submitted text or audio transcription was recognized by the Diatheke model as a valid intent or entity.\n    Message: ReplyEvent A ReplyEvent occurs when Diatheke has a reply in the conversation (not to be confused with the server concepts of request and response). These correspond to \u0026ldquo;say\u0026rdquo; entries in the Diatheke model. For example, it might be a prompt for additional information from the user, a status update, or a confirmation. ReplyEvents are not generated in response to StreamTTS calls.\n   Field Type Label Description     text string  Text of the reply event (defined by the Diatheke model).\n   label string  Label of the reply event (defined by the Diatheke model).\n    Message: SessionID Simple message that only contains the session ID.\n   Field Type Label Description     session_id string  Session ID returned from the NewSession call.\n    Message: TTSRequest Request to synthesize speech unrelated to a session.\n   Field Type Label Description     model string  The model to use for TTS (defined in the server config file).\n   text string  Text to synthesize\n    Message: TTSResponse Response for text-to-speech unrelated to a session.\n   Field Type Label Description     data bytes  The synthesized audio data. The data encoding will match what was specified in the server configuration.\n    Message: VersionResponse The message sent by the server for the Version method.\n   Field Type Label Description     server string  Server that manages all of the the other components.\n    Enum: CommandStatus.StatusCode CommandStatus are the resulting states of a command.\n   Name Number Description     SUCCESS 0 SUCCESS indicates that the command was successfully completed, and the dialog state may now move on to the next state.   FAILURE 1 FAILURE indicates that the command was not successfully completed, and the dialog state should be updated accordingly.    Scalar Value Types    .proto Type Notes Go Type Python Type C++ Type     double  float64 float double   float  float32 float float   int32 Uses variable-length encoding. Inefficient for encoding negative numbers  if your field is likely to have negative values, use sint32 instead. int32 int int32   int64 Uses variable-length encoding. Inefficient for encoding negative numbers  if your field is likely to have negative values, use sint64 instead. int64 int/long int64   uint32 Uses variable-length encoding. uint32 int/long uint32   uint64 Uses variable-length encoding. uint64 int/long uint64   sint32 Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int32s. int32 int int32   sint64 Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int64s. int64 int/long int64   fixed32 Always four bytes. More efficient than uint32 if values are often greater than 2^28. uint32 int uint32   fixed64 Always eight bytes. More efficient than uint64 if values are often greater than 2^56. uint64 int/long uint64   sfixed32 Always four bytes. int32 int int32   sfixed64 Always eight bytes. int64 int/long int64   bool  bool boolean bool   string A string must always contain UTF-8 encoded or 7-bit ASCII text. string str/unicode string   bytes May contain any arbitrary sequence of bytes. []byte str string    "
},
{
	"uri": "https://cobaltspeech.github.io/sdk-diatheke/glossary/",
	"title": "Glossary",
	"tags": [],
	"description": "",
	"content": " Action When a user says something, it is converted to intents and entities. Then, the system can take any action in response. Actions can include text-to-speech output, or running a specific command.\nFor example, if someone asks to pay money off their credit card, then the system should interact with the banking backend to pay the card, while also playing a TTS response to confirm to the user what is happening.\nASR The first step in any dialogue system is Automatic Speech Recognition (ASR), which converts the audio of someone\u0026rsquo;s utterance into text. ASR usually outputs in \u0026lsquo;spoken form\u0026rsquo;, i.e. numbers and other expressions are in words, not digits (\u0026ldquo;three hundred and twenty one\u0026rdquo; and not \u0026ldquo;321\u0026rdquo;), but automatic formatting can optionally be applied.\nDiatheke uses Cobalt\u0026rsquo;s ASR engine, Cubic, to process audio and supply transcripts.\nCommand A command is a specific type of action that executes some set of tasks in response to a recognized intent. For example, if the utterance \u0026ldquo;Play some music\u0026rdquo; was recognized as an intent, the command might handle the actual playback of an audio file.\nEntity An entity (a.k.a. a slot) appears in an utterance. It represents a value in an intent that can change between utterances or even be omitted entirely in some cases. Entities are defined in the Diatheke model.\nExamples 1. \"What's the weather forecast for Paris?\"  2. \"Book me three plane tickets from London to New York, please.\"  3. \"Play the song New York\"  4. \"Pay three pounds off my credit card.\"   \nThe first two examples have entities that are cities - the first has a single City, while the second might have a SourceCity and DestinationCity.\nThe second and fourth examples have entities that are numbers, though they are interpreted differently in the two utterances. One is a quantity, and the other is an amount of money.\nThe same words can mean different entities in different contexts. E.g. \u0026lsquo;New York\u0026rsquo; could be either a City or a SongName, depending on the context.\nIntent Intent is the name for a group of utterances which mean the same sort of thing and result in a particular action being taken. Intents are defined as part of the Diatheke model.\nExample - GetWeatherForecastIntent \"What's the weather forecast for Paris?\"  \"What's the weather like in London?\"  \"Is it going to be sunny today?\"   \nExample - BookTicketIntent \"Book me three plane tickets from London to New York, please.\"  \"Book me two train tickets from Newcastle to Edinburgh.\"  \"Book me five bus tickets to Grand Junction.\"   \nNLU Natural Language Understanding (NLU) is a field within artificial intelligence that deals with machine reading comprehesion. It attempts to discern the meaning of (sometimes incomplete) sentences. In Diatheke, these interpretations are the intent with its associated entites.\nSession A session represents all the components (ASR, TTS, NLU, etc.) necessary to carry on a conversation with Diatheke. A single session keeps track of a dialog\u0026rsquo;s current state, with all possible states being defined by a Diatheke model.\nSlot See Entity\nTTS Text To Speech (TTS) synthesizes audio that replicates human speech from written text.\nDiatheke uses Cobalt\u0026rsquo;s TTS engine, Luna, to process audio and supply transcripts.\nUtterance An utterance is something that someone says - it isn\u0026rsquo;t necessarily a full sentence as people don\u0026rsquo;t always speak grammatically.\nExamples \"What's the weather forecast?\"  \"Book me a train ticket, please\"  \"Play some music\"  \"Pay my credit card balance in full\"  \"Cancel\"   \n"
},
{
	"uri": "https://cobaltspeech.github.io/sdk-diatheke/_header/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "Diatheke SDK \u0026ndash; Cobalt\n"
},
{
	"uri": "https://cobaltspeech.github.io/sdk-diatheke/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cobaltspeech.github.io/sdk-diatheke/",
	"title": "Diatheke SDK Documentation",
	"tags": [],
	"description": "",
	"content": " Diatheke API Overview Diatheke is Cobalt\u0026rsquo;s dialog management engine. It uses a combination of speech technologies and artificial intelligence to allow users to interact with computers and mobile devices through audio and text based dialogs.\nAudio Based Dialogs Audio based dialog management uses multiple speech technologies, including Automatic Speech Recognition (ASR), Natural Language Understanding (NLU), and Text To Speech (TTS). It starts with audio input from a client application (human speech), which Diatheke sends to the ASR engine to get a transcription. This transcription is passed on to the NLU engine, which converts the transcription into an intent and entities. The intent and entites are then used to perform an action, as defined by the Diatheke model. One such action is for Diatheke to send a reply to the user. The reply text is sent to the TTS engine, which then synthesizes audio to send back to the client, as shown below.\nmermaid.initialize({startOnLoad:true}); graph LR; subgraph Diatheke A[ASR] --|Transcription| B[NLU] B --|Intents and Entities| C[DialogModel] C --|Reply| D[TTS] end E[ClientApplication] ==|Audio Input| A D ==|Synthesized Audio| E  Text Based Dialogs Diatheke is also capable of processing dialogs without using audio input or output. In this case, text is sent to Diatheke, which forwards it directly to the NLU engine and converts the text to an intent and entities, as it did with the transcription in the audio workflow. The intent and entities are used to perform an action, such as sending a reply to the client application in the form of text, as shown below.\nmermaid.initialize({startOnLoad:true}); graph LR; subgraph Diatheke A[NLU] --|Intents and Entities| B[DialogModel] end C[ClientApplication] ==|Text Input| A B ==|Reply Text| C  Commands Diatheke uses an event stream to notify the client application when significant events happen in Diatheke. The most important of these events is the Command event, which represents a request from the server for the client application to execute a command defined in the Diatheke model. The client in turn notifies Diatheke when the command has finished, as shown below.\nmermaid.initialize({startOnLoad:true}); graph LR; subgraph Audio based A[ClientApplication] --|Audio Input| B[Diatheke] B --|Command| A A --|Command Result| B B --|Synthesized Audio| A end subgraph Text based C[ClientApplication] --|Text input| D[Diatheke] D --|Command| C C --|Command Result| D D --|Reply Text| C end  "
},
{
	"uri": "https://cobaltspeech.github.io/sdk-diatheke/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]